{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/zzh8829/yolov3-tf2/blob/master/colab_gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "51bQlVgjmnWf"
   },
   "source": [
    "# YoloV3 TF2 GPU Colab Notebook\n",
    "\n",
    "##### 1.  Clone and install dependencies \n",
    "\n",
    "**IMPORTANT**: Restart following the instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "cpn-5i4VHbht",
    "outputId": "7b1b96df-f538-4bfc-d1f3-e686cc56a493",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/artem-oppermann/object-detection\n",
    "%cd object-detection/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EIUMAdGXm46J"
   },
   "source": [
    "##### 2.  Check Tensorflow2 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "oyrsdB9THu-8",
    "outputId": "a0b04911-7396-4807-af0d-04975315ac77"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow-gpu==2.1.0\n",
    "!pip install opencv-python==4.1.1.26\n",
    "!pip install lxml\n",
    "!pip install tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Up4Xcad81FSa"
   },
   "source": [
    "##### 3. Training New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "-I8Ml-j4Iyuv",
    "outputId": "a1880906-4c01-4f08-a12b-ca2f37582a55"
   },
   "outputs": [],
   "source": [
    "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2009/VOCtrainval_11-May-2009.tar -O ./data/voc2009_raw.tar\n",
    "!mkdir -p ./data/voc2009_raw\n",
    "!tar -xf ./data/voc2009_raw.tar -C ./data/voc2009_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "9lvttM39I5Na",
    "outputId": "faa0df6f-ab49-4476-b2e7-de3c4dbdb5d3"
   },
   "outputs": [],
   "source": [
    "!python tools/voc2012.py \\\n",
    "  --data_dir './data/voc2009_raw/VOCdevkit/VOC2009' \\\n",
    "  --split train \\\n",
    "  --output_file ./data/voc_train.tfrecord\n",
    "\n",
    "!python tools/voc2012.py \\\n",
    "  --data_dir './data/voc2009_raw/VOCdevkit/VOC2009' \\\n",
    "  --split val \\\n",
    "  --output_file ./data/voc_val.tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "colab_type": "code",
    "id": "ZBhryo1I2dwG",
    "outputId": "79963b6f-7f30-4a3d-dd83-792ed28a790d"
   },
   "outputs": [],
   "source": [
    "!python train.py \\\n",
    "\t--dataset ./data/voc_train.tfrecord \\\n",
    "\t--val_dataset ./data/voc_val.tfrecord \\\n",
    "\t--classes ./data/class_names/voc2012.names \\\n",
    "\t--num_classes 20 \\\n",
    "\t--mode fit --transfer none \\\n",
    "\t--batch_size 16 \\\n",
    "\t--epochs 10 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from absl import app, flags, logging\n",
    "from absl.flags import FLAGS\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from core.models import YoloV3\n",
    "\n",
    "from core.dataset import transform_images, load_tfrecord_dataset\n",
    "from core.utils import draw_outputs\n",
    "\n",
    "flags.DEFINE_string('classes', './data/class_names/voc2012.names', 'path to classes file')\n",
    "flags.DEFINE_string('weights', './checkpoints/yolov3.tf',\n",
    "                    'path to weights file')\n",
    "flags.DEFINE_integer('image_size', 416, 'resize images to')\n",
    "flags.DEFINE_string('image', './data/evaluation/autos.jpg', 'path to input image')\n",
    "flags.DEFINE_string('tfrecord', None, 'tfrecord instead of image')\n",
    "flags.DEFINE_string('output', './output.jpg', 'path to output image')\n",
    "flags.DEFINE_integer('num_classes', 80, 'number of classes in the model')\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "    \n",
    "    if len(physical_devices) > 0:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS.num_classes = 20\n",
    "FLAGS.classes = 'data/class_names/voc2012.names'\n",
    "FLAGS.weights = 'checkpoints/yolov3_train_3.tf'\n",
    "FLAGS.image = './data/evaluation/autos.jpg'\n",
    "\n",
    "# Lower threshold due to insufficient training\n",
    "FLAGS.yolo_iou_threshold = 0.2\n",
    "FLAGS.yolo_score_threshold = 0.2\n",
    "\n",
    "\n",
    "yolo = YoloV3(classes=FLAGS.num_classes)\n",
    "\n",
    "yolo.load_weights(FLAGS.weights).expect_partial()\n",
    "logging.info('weights loaded')\n",
    "\n",
    "class_names = [c.strip() for c in open(FLAGS.classes).readlines()]\n",
    "logging.info('classes loaded')\n",
    "\n",
    "img_raw = tf.image.decode_image(\n",
    "    open(FLAGS.image, 'rb').read(), channels=3)\n",
    "\n",
    "img = tf.expand_dims(img_raw, 0)\n",
    "img = transform_images(img, FLAGS.size)\n",
    "\n",
    "t1 = time.time()\n",
    "boxes, scores, classes, nums = yolo(img)\n",
    "t2 = time.time()\n",
    "logging.info('time: {}'.format(t2 - t1))\n",
    "\n",
    "logging.info('detections:')\n",
    "for i in range(nums[0]):\n",
    "    logging.info('\\t{}, {}, {}'.format(class_names[int(classes[0][i])],\n",
    "                                        np.array(scores[0][i]),\n",
    "                                        np.array(boxes[0][i])))\n",
    "\n",
    "img = cv2.cvtColor(img_raw.numpy(), cv2.COLOR_RGB2BGR)\n",
    "img = draw_outputs(img, (boxes, scores, classes, nums), class_names)\n",
    "\n",
    "from IPython.display import Image, display\n",
    "display(Image(data=bytes(cv2.imencode('.jpg', img)[1]), width=800))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "colab_gpu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
